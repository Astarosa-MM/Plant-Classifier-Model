# -*- coding: utf-8 -*-
"""Plant Species Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r0XGG27c1IHr660MaoENv6AWACSJCP1p
"""

# Plant Species Classifier

from google.colab import drive
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import random
import shutil

# Mount Google Drive
drive.mount('/content/drive')

# Balancing the dataset
original_base = "/content/drive/MyDrive/plant_classifier_dataset/train"
balanced_base = "/content/drive/MyDrive/plant_classifier_dataset/balanced_flowers"

os.makedirs(balanced_base, exist_ok=True)
target_count = 495  # Inputting dataset's smallest category size

for class_name in os.listdir(original_base):
    class_path = os.path.join(original_base, class_name)
    image_files = os.listdir(class_path)
    selected_images = random.sample(image_files, target_count)

    dest_class_path = os.path.join(balanced_base, class_name)
    os.makedirs(dest_class_path, exist_ok=True)

    for img_file in selected_images:
        src = os.path.join(class_path, img_file)
        dst = os.path.join(dest_class_path, img_file)
        shutil.copy2(src, dst)

    print(f"Copied {len(selected_images)} images to {dest_class_path}")

# Define dataset path
base_dir = balanced_base

# Inspect classes
class_folders = os.listdir(base_dir)
print("Classes found:", class_folders)
for class_name in class_folders:
    class_path = os.path.join(base_dir, class_name)
    num_images = len(os.listdir(class_path))
    print(f"{class_name}: {num_images} images")

# Data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Load or build model
model_path = "plant_species_classifier.h5"
if os.path.exists(model_path):
    print("Loading existing model...")
    model = load_model(model_path)
    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
else:
    print("Building new model...")
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.3)(x)
    predictions = Dense(train_generator.num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# EarlyStopping
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

# Train or continue training
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=30,
    callbacks=[early_stop]
)

# Save the model
model.save(model_path)

# Plot training results
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Classification report
eval_loss, eval_acc = model.evaluate(val_generator)
print(f"\nValidation Accuracy: {eval_acc:.4f}")
print(f"Validation Loss: {eval_loss:.4f}")

y_pred = model.predict(val_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes, target_names=class_labels))

cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()